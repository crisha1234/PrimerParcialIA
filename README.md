# RAMOS MAMANI CRISHMAN COM300 PRIMER PARCIAL
‚úÖ Ventajas de usar una red neuronal en PyTorch

    Abstracci√≥n de bajo nivel + flexibilidad:

        Puedes definir arquitecturas complejas sin programar toda la retropropagaci√≥n manualmente.

    Uso de GPU:

        PyTorch permite aprovechar aceleraci√≥n por GPU f√°cilmente (.to(device)), lo que acelera mucho el entrenamiento.

    Optimizaci√≥n autom√°tica (autograd):

        No necesitas implementar el c√°lculo de gradientes manualmente; PyTorch lo hace con loss.backward().

    Integraci√≥n con datasets e im√°genes:

        Soporte directo para torchvision.datasets, transformaciones y loaders, ideal para im√°genes.

    Depuraci√≥n m√°s sencilla:

        Puedes imprimir y monitorear estados internos f√°cilmente, incluso insertar puntos de interrupci√≥n.

‚ö†Ô∏è Desventajas (o retos) de usar PyTorch

    Curva de aprendizaje:

        Puede ser m√°s complejo para principiantes que una implementaci√≥n b√°sica en NumPy.

    Menos control expl√≠cito:

        Si est√°s aprendiendo teor√≠a, PyTorch te oculta detalles importantes como derivadas parciales o c√≥mo fluye el gradiente.

    Dependencia de entorno:

        Requiere instalaci√≥n de librer√≠as y configuraci√≥n adecuada del entorno, especialmente para GPU.

üîç Diferencias clave con un algoritmo de clasificaci√≥n con retropropagaci√≥n "generalizado" (hecho desde cero)
Aspecto	PyTorch (como en tu c√≥digo)	Implementaci√≥n Generalizada (NumPy/Scipy)
Retropropagaci√≥n	Autom√°tica (autograd)	Manual (t√∫ calculas los gradientes)
Entrenamiento en GPU	S√≠	No (solo CPU, m√°s lento)
Escalabilidad	Alta	Limitada (dif√≠cil escalar a grandes datasets)
Modularidad	Alta (modelos, optimizadores, transformaciones)	Baja o manual
Facilidad para debugging educativo	Media	Alta (ves todo lo que ocurre)
üéì ¬øCu√°ndo usar cada uno?

    Para aprender conceptos: Mejor implementar desde cero con NumPy.

    Para aplicaciones reales: Mejor usar PyTorch por su eficiencia, comunidad y escalabilidad.
